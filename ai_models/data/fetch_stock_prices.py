import requests
import pandas as pd
from datetime import datetime, timedelta
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict

def get_date_range():
    """
    ê³ ì •ëœ ì¢…ë£Œì¼(20250321)ê³¼ ê·¸ë¡œë¶€í„° 500ì¼ ì „ì˜ ì‹œì‘ì¼ì„ ê³„ì‚°í•˜ì—¬ ë°˜í™˜
    """
    end_date = datetime.strptime('20250321', '%Y%m%d')
    # 500 ê±°ë˜ì¼ (ì•½ 2ë…„ ì •ë„ì§€ë§Œ ì •í™•íˆ 500ì¼ë¡œ ì„¤ì •)
    start_date = end_date - timedelta(days=500)
    return start_date.strftime('%Y%m%d'), end_date.strftime('%Y%m%d')

def fetch_stock_data(stock_code, stock_name, api_key, base_url, begin_date, end_date):
    """
    ë‚ ì§œ ë²”ìœ„ë¥¼ ì§€ì •í•˜ì—¬ í•œ ë²ˆì— ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    """
    try:
        params = {
            'serviceKey': api_key,
            'resultType': 'json',
            'itmsNm': stock_name,
            'numOfRows': '1000',  # ìµœëŒ€ row ìˆ˜
            'pageNo': '1',
            'beginBasDt': begin_date,
            'endBasDt': end_date
        }
        
        response = requests.get(base_url + "/getStockPriceInfo", 
                                params=params, 
                                verify=False)  # SSL ê²€ì¦ ë¹„í™œì„±í™”
        
        response.raise_for_status()
        
        data = response.json()
        
        if (data.get('response', {}).get('body', {}).get('totalCount', 0) > 0 and 
            'items' in data['response']['body']):
            items = data['response']['body']['items'].get('item', [])
            
            if not isinstance(items, list):
                items = [items]
            
            df = pd.DataFrame(items)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            columns = ['basDt', 'srtnCd', 'itmsNm', 'clpr', 'vs', 'fltRt', 'mkp', 'hipr', 'lopr', 'trqu', 'mrktTotAmt']
            df = df[columns]
            
            column_names = {
                'basDt': 'ê¸°ì¤€ì¼ì',
                'srtnCd': 'ì¢…ëª©ì½”ë“œ',
                'itmsNm': 'ì¢…ëª©ëª…',
                'clpr': 'í˜„ì¬ê°€',
                'vs': 'ì „ì¼ëŒ€ë¹„',
                'fltRt': 'ë“±ë½ë¥ ',
                'mkp': 'ì‹œê°€',
                'hipr': 'ê³ ê°€',
                'lopr': 'ì €ê°€',
                'trqu': 'ê±°ë˜ëŸ‰',
                'mrktTotAmt': 'ì‹œê°€ì´ì•¡'
            }
            df = df.rename(columns=column_names)
            
            numeric_columns = ['í˜„ì¬ê°€', 'ì „ì¼ëŒ€ë¹„', 'ë“±ë½ë¥ ', 'ê±°ë˜ëŸ‰', 'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'ì‹œê°€ì´ì•¡']
            for col in numeric_columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            df = df.drop_duplicates(subset=['ê¸°ì¤€ì¼ì', 'ì¢…ëª©ì½”ë“œ'])
            
            # í˜ì´ì§• ì²˜ë¦¬ - APIê°€ 1000ê°œ ì´ìƒì˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•  ê²½ìš°
            total_count = data['response']['body']['totalCount']
            if total_count > 1000:
                total_pages = (total_count + 999) // 1000  # ì˜¬ë¦¼ ë‚˜ëˆ—ì…ˆ
                additional_dfs = []
                
                for page in range(2, total_pages + 1):
                    params['pageNo'] = str(page)
                    
                    try:
                        page_response = requests.get(base_url + "/getStockPriceInfo", 
                                                   params=params, 
                                                   verify=False)
                        page_response.raise_for_status()
                        page_data = page_response.json()
                        
                        if (page_data.get('response', {}).get('body', {}).get('totalCount', 0) > 0 and 
                            'items' in page_data['response']['body']):
                            page_items = page_data['response']['body']['items'].get('item', [])
                            
                            if not isinstance(page_items, list):
                                page_items = [page_items]
                            
                            page_df = pd.DataFrame(page_items)
                            page_df = page_df[columns]
                            page_df = page_df.rename(columns=column_names)
                            
                            for col in numeric_columns:
                                page_df[col] = pd.to_numeric(page_df[col], errors='coerce')
                            
                            additional_dfs.append(page_df)
                    except Exception as e:
                        print(f"ì¶”ê°€ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
                
                if additional_dfs:
                    additional_df = pd.concat(additional_dfs, ignore_index=True)
                    df = pd.concat([df, additional_df], ignore_index=True)
                    df = df.drop_duplicates(subset=['ê¸°ì¤€ì¼ì', 'ì¢…ëª©ì½”ë“œ'])
            
            return df, total_count
        
        return None, 0
    
    except requests.exceptions.RequestException as e:
        print(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, 0
    except Exception as e:
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, 0

def fetch_stock_prices():
    # ë””ì½”ë”©ëœ API í‚¤
    api_key = "Br3pycEHLqE+tbM3H74ZHJhDxUwtJrwoAER9rltjFnMMV6Aibf4zOOomChkZIgiwYwvX3BuGWHvHWlCFXWy04A=="
    base_url = "http://apis.data.go.kr/1160100/service/GetStockSecuritiesInfoService"
    
    # requestsì˜ SSL ê²½ê³  ë¹„í™œì„±í™”
    requests.packages.urllib3.disable_warnings(
        requests.packages.urllib3.exceptions.InsecureRequestWarning
    )
    
    # ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ì„¤ì •
    begin_date, end_date = get_date_range()
    print(f"ğŸ“† ì¡°íšŒ ê¸°ê°„: {begin_date} ~ {end_date}")
    
    try:
        kospi200_df = pd.read_csv('kospi200_and_related.csv')
        kospi200_df['ì¢…ëª©ì½”ë“œ'] = kospi200_df['ì¢…ëª©ì½”ë“œ'].astype(str).str.replace('A', '', regex=False)
    except Exception as e:
        print(f"KOSPI ì¢…ëª© ë¦¬ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return None
    
    # ì¢…ëª©ë³„ ë°ì´í„°ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    all_stock_data = []
    
    # ì¢…ëª©ë³„ ì§„í–‰ ìƒí™©ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    total_api_calls = 0
    total_records = 0
    success_count = 0
    fail_count = 0
    
    with ThreadPoolExecutor(max_workers=10) as executor:
        future_to_stock = {}
        
        for _, row in kospi200_df.iterrows():
            stock_code = row['ì¢…ëª©ì½”ë“œ']
            stock_name = row['ì¢…ëª©ëª…']
            future = executor.submit(fetch_stock_data, stock_code, stock_name, 
                                    api_key, base_url, begin_date, end_date)
            future_to_stock[future] = (stock_code, stock_name)
        
        for i, future in enumerate(as_completed(future_to_stock)):
            stock_code, stock_name = future_to_stock[future]
            try:
                df, total_count = future.result()
                total_api_calls += 1  # ê¸°ë³¸ API í˜¸ì¶œ 1íšŒ
                
                # í˜ì´ì§•ì´ ìˆì—ˆë‹¤ë©´ ì¶”ê°€ API í˜¸ì¶œ íšŸìˆ˜ ê³„ì‚°
                if total_count > 1000:
                    total_pages = (total_count + 999) // 1000
                    total_api_calls += (total_pages - 1)
                
                if df is not None and not df.empty:
                    # ì¢…ëª©ëª… ì¼ê´€ì„± ìœ ì§€
                    df['ì¢…ëª©ëª…'] = stock_name
                    all_stock_data.append(df)
                    total_records += len(df)
                    success_count += 1
                    print(f"âœ… ({i+1}/{len(kospi200_df)}) {stock_name}({stock_code}) - {len(df)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                else:
                    fail_count += 1
                    print(f"âŒ ({i+1}/{len(kospi200_df)}) {stock_name}({stock_code}) - ë°ì´í„° ì—†ìŒ")
            except Exception as e:
                fail_count += 1
                print(f"âš ï¸ ({i+1}/{len(kospi200_df)}) {stock_name}({stock_code}) - ì˜¤ë¥˜: {e}")
    
    if all_stock_data:
        # ëª¨ë“  ì£¼ê°€ ë°ì´í„° í•©ì¹˜ê¸°
        combined_df = pd.concat(all_stock_data, ignore_index=True)
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        combined_df['ê¸°ì¤€ì¼ì'] = pd.to_datetime(combined_df['ê¸°ì¤€ì¼ì'], format='%Y%m%d')
        
        # í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ì €ì¥ (ì¢…ëª©ë³„ë¡œ ì •ë ¬)
        combined_df = combined_df.sort_values(['ì¢…ëª©ì½”ë“œ', 'ê¸°ì¤€ì¼ì'])
        
        # íŒŒì¼ëª…ì— ì €ì¥ ë‚ ì§œì™€ ê¸°ê°„ í¬í•¨
        save_date = datetime.now().strftime('%Y%m%d')
        filename = f'kospi200_stock_prices_{begin_date}_{end_date}_{save_date}.csv'
        combined_df.to_csv(filename, index=False, encoding='utf-8-sig')
        
        print(f"\nğŸ’¾ ëª¨ë“  ë°ì´í„°ê°€ '{filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ“Š í†µê³„:")
        print(f"   - ì´ API í˜¸ì¶œ íšŸìˆ˜: {total_api_calls}íšŒ")
        print(f"   - ì„±ê³µí•œ ì¢…ëª© ìˆ˜: {success_count}/{len(kospi200_df)}")
        print(f"   - ìˆ˜ì§‘ëœ ë°ì´í„° ë ˆì½”ë“œ ìˆ˜: {total_records}ê°œ")
        
        return combined_df
    else:
        print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

if __name__ == "__main__":
    print("ğŸ“¢ KOSPI200 ì£¼ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    stock_data = fetch_stock_prices()
    if stock_data is not None:
        print(f"âœ… ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ ì™„ë£Œ!")
    else:
        print("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨!")